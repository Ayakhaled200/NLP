{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNKR2rJZ+Q3tEwg+ND63tit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayakhaled200/NLP/blob/main/Generating_Poetic_Texts_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4p6fu18iwkw"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = tf.keras.utils.get_file('shakespeare.txt ','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "eN9X11kfsfDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: later our model will predict the next character, if we allow for upper case characters, it has way more possible choices so the accuracy is't going to be great, so we can increase the performance by only using lower case letters.\n",
        "####ofcourse that might not be good for the grammer, but as contant -semmantic- wise, it doesn't make a difference."
      ],
      "metadata": {
        "id": "o0MXygKQ2x3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(file_path, 'rb').read().decode(encoding='utf_8').lower()   #open in read binary mode"
      ],
      "metadata": {
        "id": "qxExeKIX1_xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert the text into numeric formate to feed it as np array to the RNN"
      ],
      "metadata": {
        "id": "phPy9c_p4Ksi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting part of the text\n",
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "qQB6KYNK4Ax_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''creating a character set which contains all the possible characters that occur somewhere in the text\n",
        "if the char didn't appear in the section we selected, it's not going to be in the set'''\n",
        "characters = sorted(set(text))"
      ],
      "metadata": {
        "id": "JvgMBZDw4uSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((c,i) for i, c in enumerate(characters)) #assign number to each char in the set"
      ],
      "metadata": {
        "id": "-bUxWWg26oxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = dict((i,c) for i, c in enumerate(characters)) #assign char to each number"
      ],
      "metadata": {
        "id": "_6QvdhY67gv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####How many characters are we going to use as features in order to predict the next character\n",
        "######careful, you don't want your network to rely on to much data."
      ],
      "metadata": {
        "id": "P87Wm54W8gyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 40\n",
        "step_size = 3 #how many char are we going to shift to the next sentence"
      ],
      "metadata": {
        "id": "S2KTqCFgqXat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we load a sentence into the NN and the result will be th following char\n",
        "sentences = [] #the features                    #ex:sentences:'how are yo'\n",
        "next_characters = [] #the target                #next_characters:'u' as it complete the sentences"
      ],
      "metadata": {
        "id": "9u-Wqa3V7d0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepration for Training Data"
      ],
      "metadata": {
        "id": "thga6QcjHTMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We wanna have training examples (bunch of sentences), and the next correct letter"
      ],
      "metadata": {
        "id": "6xj7gDAuADo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - seq_len, step_size):\n",
        "    sentences.append(text[i : i+seq_len])    #if the seq_len is 5 we are getting char 0 up until 4\n",
        "    next_characters.append(text[i+seq_len])    #and then char with index 5 is the next char"
      ],
      "metadata": {
        "id": "frGTxSsTp6DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert the train data into numpy"
      ],
      "metadata": {
        "id": "SScSynWoAc5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Whenever in a specific sentence at a specific position a certain character occurs, we're going to set that to true or 1, and all the other values will remain 0"
      ],
      "metadata": {
        "id": "u2bcDpsCUigv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex: Having sentence number 5, at position number 7 we have the charater with the enumeration of 8, we say x[5,7,8] = 1,\n",
        "in this formate training data is beeing passed to the NN"
      ],
      "metadata": {
        "id": "MHCmXXDmVYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), seq_len, len(characters)), dtype=np.bool_)"
      ],
      "metadata": {
        "id": "88G0GSSJ_xH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''which is the character which would be the next for which sentence\n",
        "ex: at sentence 5 the next char would be the one with enumeration 8'''\n",
        "y = np.zeros((len(sentences), len(characters)), dtype = np.bool_)"
      ],
      "metadata": {
        "id": "tQI397lp_xEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N0JOx_AyiQR",
        "outputId": "7aa60b96-c0a5-4304-8820-98730f2b7e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(166654, 40, 39)\n",
            "(166654, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):  #assigning index to every sentence\n",
        "  for t, character in enumerate(sentence):\n",
        "      X[i,t,char_to_index[character]] = 1  #sentence num i at position num t and char num whatever, this whole position is set to 1\n",
        "  y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "ZIA_o5M2_w5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the model"
      ],
      "metadata": {
        "id": "VEKVgDY2HXfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (seq_len, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer = RMSprop(lr = 0.01))\n",
        "model.fit(X,y,batch_size =256, epochs=10)\n",
        "model.save('textgenetator.model')"
      ],
      "metadata": {
        "id": "JAHPkUYxugYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d030d405-b739-4842-f2c9-3e902079e970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "651/651 [==============================] - 6s 6ms/step - loss: 2.6965\n",
            "Epoch 2/10\n",
            "651/651 [==============================] - 4s 5ms/step - loss: 2.2969\n",
            "Epoch 3/10\n",
            "651/651 [==============================] - 4s 6ms/step - loss: 2.1791\n",
            "Epoch 4/10\n",
            "651/651 [==============================] - 4s 6ms/step - loss: 2.0976\n",
            "Epoch 5/10\n",
            "651/651 [==============================] - 4s 5ms/step - loss: 2.0296\n",
            "Epoch 6/10\n",
            "651/651 [==============================] - 4s 5ms/step - loss: 1.9676\n",
            "Epoch 7/10\n",
            "651/651 [==============================] - 4s 6ms/step - loss: 1.9183\n",
            "Epoch 8/10\n",
            "651/651 [==============================] - 4s 5ms/step - loss: 1.8768\n",
            "Epoch 9/10\n",
            "651/651 [==============================] - 4s 6ms/step - loss: 1.8400\n",
            "Epoch 10/10\n",
            "651/651 [==============================] - 4s 6ms/step - loss: 1.8075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('textgenetator.model')"
      ],
      "metadata": {
        "id": "AVa1idavF2ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''the function takes the predictions of our model and picks one character\n",
        "having the softmax results of the different probabilities for each char, the function\n",
        "choose one of them depending on the tempreture\n",
        "the choice of picking is either conservative or experimental\n",
        "high temp -> char that is more risky and experimental\n",
        "low temp -> safe pick\n",
        "so the higher the temp the more creative the sentenes but maybe they're not going\n",
        "to make a lot of sense\n",
        "'''\n",
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)/temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds/ np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "_1pGJc8cugRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text Generation function"
      ],
      "metadata": {
        "id": "5Xb0RIntvxtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here we are going to start with a starting text and it's going to provid the input\n",
        "for our NN to predict the FIRST next char\n",
        "somewhere in the text we pick an entry point and take the first 40 characters\n",
        "'''\n",
        "def Generate_Text(length, tempreture):\n",
        "   start_index = random.randint(0, len(text) - seq_len - 1) #random start index\n",
        "   generated_text = ''\n",
        "   sentence = text[start_index: start_index + seq_len ]\n",
        "   generated_text += sentence\n",
        "   for i in range(length):\n",
        "      x = np.zeros((1, seq_len, len(characters)))\n",
        "      for i, character in enumerate(sentence):\n",
        "        x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "      predictions = model.predict(x, verbose = 0)[0]\n",
        "      next_index = sample(predictions, tempreture)\n",
        "      next_character = index_to_char[next_index]\n",
        "\n",
        "      generated_text += next_character #include that next char in the next input\n",
        "      sentence = sentence[1:] + next_character\n",
        "\n",
        "   return generated_text"
      ],
      "metadata": {
        "id": "FRWKv_W8vxCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Generate_Text(300, 0.2))"
      ],
      "metadata": {
        "id": "QwLWRzufOee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1c3d65-62a1-444e-f097-db4f9706eac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ur blushes and present yourself\n",
            "that whieeeeeeeeeeeeeetetttttnttttiaaatnnnnnnnnngnnnnnnnnnnnnnnnnn tnttttgnhiteeannnttnnnnnnnnnnnnntnnnnntn nnnnntttdrddyooooooooooooooooooooooooooo ooooooooowoohwwnthohooohooooooohooohhooo ooooooittnotttttttttttttttttttttttttttttonroooourr rtttrttttttttrtrttrttttttttttttrnttttooou tttttttttttttttrtttrttttt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generate_Text(300,0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "-tyQzJ3lT4iS",
        "outputId": "60c6d698-6ed4-436d-88ad-62517d683e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'when i was king of england?\\n\\nsecond keepiiiiiaiilraiiiararikyeiikddsi,                               n e t tchatttttttytttttttitttteteetteottrrrrrr rnnooooooooddddddddrrrrrwoannwyisisnonon ssnnnstossissiniiinhootttt oootttttttttttttttttttttttttttttwhhhhhhh, haintiitinhticthhhhhhhhhhihhhhhttttttttttteeeeeeeeeeeeeeeeeeancttt ttttthttritcttt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generate_Text(300,0.6)"
      ],
      "metadata": {
        "id": "qfnXP7FqT5sY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7170cbbf-1fef-4d20-bc1a-f462e61b8be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'on.\\n\\nking richard ii:\\nwhy uncle, thou ha      i          nr  t   drrt rgrrnrceeseheeeeeaeeieeetreeeeeeeeeeeeho rtttttttntnngvirneeeeeeeeeeeeeoarnnninrnnrnnn nnnnnnnndvdvvgnvrnrnnnnnceeeeeeayeieeaigeeeeeeeeeeeeeeearrk nninennnnnnnnnnnnnnnnnnnnnnnnnndnnnnenndddd dddddddddddddddddddddddddddddddddgounrruurr grrrrrrrrrrerrrrrrrrrrrrrrrrrrrrrrn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generate_Text(300,0.8)"
      ],
      "metadata": {
        "id": "JsGRxPLPT5o-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c1325410-533e-4dc9-b3cd-16af57152aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"he did us all,\\nand that will quickly dryitiiiieeiiieieieeyeeeeeeeeeanine.  d ivis!.\\nc\\natchh\\ns.io. :\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntt\\nh\\nh\\n\\n\\n\\n\\n\\n\\n\\n\\ni\\nattctngecriennnrtrorrrrnnnrrnndrnnrrndrrroorrorr. n w  uwddnndgeinnnnnnnnnnfn'rndnadnddendcrceneegdddddddddddrddled ddrcdriarddkrniieidiaayvieeeeiieeeeeeeeeeeee cieeiieonrnrvyvvroeoenenoeeeoeseeoeeecee\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generate_Text(300,1.0)"
      ],
      "metadata": {
        "id": "b87pKCfBT5mY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b986ab89-b89b-4c2f-cef4-e1fd76cb597e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' our king, my brother,\\nis prisoner to th e  e oo oso ttwtooooattnnonnnnttttittvinnnnshtittiecenin netteeatneaetetihetaetctthtttevtactacectyeeeeeeeeeeieeeeeeateenyeeelteee veaeaegieoigr oyevodeo sie;    re,                      n   \\nt chootwoohwohhohhhhahthoohinltttoiaoinatoe, tsttihitd     , i r      t rg r r     e      i   e nronrrrrgrrn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}